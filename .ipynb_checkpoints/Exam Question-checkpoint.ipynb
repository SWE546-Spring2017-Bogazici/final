{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Matrix Factorization\n",
    "\n",
    "Maximize the following :\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(W, H) = \\sum_{i=1}^I \\sum_{j=1}^J M(i,j) ( Y(i,j) \\log (\\sigma(W(i) H(j))) + (1 - Y(i,j)) \\log(1 - \\sigma(W(i) H(j))) )\n",
    "$$\n",
    "\n",
    "Observed $I\\times J$ binary matrix with possibly missing entries\n",
    "$Y(i,j) \\in \\{0,1\\}$\n",
    "\n",
    "Mask Matrix\n",
    "$M(i,j) = 1$ if $Y(i,j)$ is observed, $M(i,j) = 0$ if $Y(i,j)$ is not observed\n",
    "\n",
    "\n",
    "Here:\n",
    "\n",
    "$\\sigma(x)$ is the sigmoid function defined as\n",
    "\\begin{eqnarray}\n",
    "\\sigma(x) & = & \\frac{1}{1+e^{-x}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "### Properties of the sigmoid function\n",
    "Note that\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\sigma(x) & = & \\frac{e^x}{(1+e^{-x})e^x} = \\frac{e^x}{1+e^{x}} \\\\\n",
    "1 - \\sigma(x) & = & 1 - \\frac{e^x}{1+e^{x}} = \\frac{1+e^{x} - e^x}{1+e^{x}} = \\frac{1}{1+e^{x}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\sigma'(x) & = & \\frac{e^x(1+e^{x}) - e^{x} e^x}{(1+e^{x})^2} = \\frac{e^x}{1+e^{x}}\\frac{1}{1+e^{x}} = \\sigma(x) (1-\\sigma(x))\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\log \\sigma(x) & = & -\\log(1+e^{-x}) = x - \\log(1+e^{x}) \\\\\n",
    "\\log(1 - \\sigma(x)) & = &  -\\log({1+e^{x}})\n",
    "\\end{eqnarray}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "# Generate a random logistic regression problem\n",
    "\n",
    "def sigmoid(t):\n",
    "    return np.exp(t)/(1+np.exp(t))\n",
    "\n",
    "I = 5\n",
    "J = 10\n",
    "\n",
    "# Random Mask \n",
    "M = np.random.rand(I,J)<0.8\n",
    "\n",
    "# Random Parameters\n",
    "W = np.random.randn(I,1)\n",
    "H = np.random.randn(1,J)\n",
    "\n",
    "Y = np.zeros((I,J))\n",
    "Ycopy=Y.copy()\n",
    "# Generate class labels\n",
    "pi = sigmoid(W*H)\n",
    "\n",
    "for i in range(I):\n",
    "    for j in range(J):\n",
    "        if not M[i,j]:\n",
    "            Y[i,j] = np.nan\n",
    "        else:\n",
    "            Y[i,j] = 1 if pi[i,j] < np.random.rand() else 0\n",
    "            Ycopy[i,j]=Y[i,j]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: \n",
    "Given $Y$ and $M$ only find a good $W$ and $H$ by maximizing the objective $\\mathcal{L}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the gradient \n",
    "\n",
    "$$\n",
    "\\frac{d\\mathcal{L}(W,H)}{dW(i)} = \\sum_{j=1}^J (M(i,j) (Y(i,j) -\\sigma(W(i) H(j)))) H(j)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{d\\mathcal{L}(W,H)}{dH(j)} = \\sum_{i=1}^I  W(i) (M(i,j) (Y(i,j) -\\sigma(W(i) H(j))))\n",
    "$$\n",
    "\n",
    "\n",
    "Then use alternating gradient descent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate(W,H,Y,M,Epoch=5000,eta=0.005,nu=0.1):\n",
    "    Hfinal=H.copy()\n",
    "    Wfinal=W.copy()\n",
    "    for epoch in range(Epoch):\n",
    "        dL = np.dot(Wfinal.T, Mask*(Y-sigmoid(np.dot(Wfinal,Hfinal)))) -nu*Hfinal\n",
    "        Hfinal = Hfinal + eta*dL\n",
    "        dL = np.dot(Mask*(Y-sigmoid(np.dot(Wfinal,Hfinal))),Hfinal.T )-nu*Wfinal\n",
    "        Wfinal = Wfinal + eta*dL\n",
    "    return Wfinal,Hfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WActual:\n",
      "[[ 2.04826637]\n",
      " [-0.7602782 ]\n",
      " [ 0.75563165]\n",
      " [ 0.88721414]\n",
      " [ 1.79134377]]\n",
      "WFinal:\n",
      "[[ 3.0679268 ]\n",
      " [-3.36626686]\n",
      " [ 0.52970783]\n",
      " [ 1.34800737]\n",
      " [ 1.37717813]]\n",
      "HActual:\n",
      "[[-0.89544175  0.04669649 -1.25945893 -0.74200475  1.05699121  1.10270035\n",
      "   0.73399918  0.22991575 -0.01919862 -0.96882611]]\n",
      "HFinal:\n",
      "[[ 2.32782554 -0.40498462  2.32780981  0.67140256 -1.3123687  -2.32778463\n",
      "   0.4464312  -2.08217813  1.08266042  0.68206693]]\n",
      "[[1 0 1 1 1 1 1 0 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 0 1 1 1 1 1 0]\n",
      " [1 1 1 1 1 1 0 0 1 1]\n",
      " [1 1 1 1 1 1 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "eta=0.05\n",
    "EPOCH=5000\n",
    "Winitial = np.random.randn(I,1)\n",
    "Hinitial= np.random.randn(1,J)\n",
    "Mask=M.astype(int)\n",
    "Wfinal,Hfinal=iterate(Winitial,Hinitial,Ycopy,Mask,Epoch=5000,eta=0.005,nu=0.1)\n",
    "print(\"WActual:\",W, sep=\"\\n\")\n",
    "print(\"WFinal:\",Wfinal, sep=\"\\n\")\n",
    "print(\"HActual:\",H, sep=\"\\n\")\n",
    "print(\"HFinal:\",Hfinal, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
