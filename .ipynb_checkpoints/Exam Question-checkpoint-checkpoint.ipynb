{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Matrix Factorization\n",
    "\n",
    "Maximize the following :\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(W, H) = \\sum_{i=1}^I \\sum_{j=1}^J M(i,j) ( Y(i,j) \\log (\\sigma(W(i) H(j))) + (1 - Y(i,j)) \\log(1 - \\sigma(W(i) H(j))) )\n",
    "$$\n",
    "\n",
    "Observed $I\\times J$ binary matrix with possibly missing entries\n",
    "$Y(i,j) \\in \\{0,1\\}$\n",
    "\n",
    "Mask Matrix\n",
    "$M(i,j) = 1$ if $Y(i,j)$ is observed, $M(i,j) = 0$ if $Y(i,j)$ is not observed\n",
    "\n",
    "\n",
    "Here:\n",
    "\n",
    "$\\sigma(x)$ is the sigmoid function defined as\n",
    "\\begin{eqnarray}\n",
    "\\sigma(x) & = & \\frac{1}{1+e^{-x}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "### Properties of the sigmoid function\n",
    "Note that\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\sigma(x) & = & \\frac{e^x}{(1+e^{-x})e^x} = \\frac{e^x}{1+e^{x}} \\\\\n",
    "1 - \\sigma(x) & = & 1 - \\frac{e^x}{1+e^{x}} = \\frac{1+e^{x} - e^x}{1+e^{x}} = \\frac{1}{1+e^{x}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\sigma'(x) & = & \\frac{e^x(1+e^{x}) - e^{x} e^x}{(1+e^{x})^2} = \\frac{e^x}{1+e^{x}}\\frac{1}{1+e^{x}} = \\sigma(x) (1-\\sigma(x))\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\log \\sigma(x) & = & -\\log(1+e^{-x}) = x - \\log(1+e^{x}) \\\\\n",
    "\\log(1 - \\sigma(x)) & = &  -\\log({1+e^{x}})\n",
    "\\end{eqnarray}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "# Generate a random logistic regression problem\n",
    "\n",
    "def sigmoid(t):\n",
    "    return np.exp(t)/(1+np.exp(t))\n",
    "\n",
    "I = 5\n",
    "J = 10\n",
    "\n",
    "# Random Mask \n",
    "#M = np.random.rand(I,J)<0.8\n",
    "M = (np.random.rand(I,J)<0.8)\n",
    "\n",
    "# Random Parameters\n",
    "W = np.random.randn(I,1)\n",
    "H = np.random.randn(1,J)\n",
    "\n",
    "Y = np.zeros((I,J))\n",
    "# Generate class labels\n",
    "pi = sigmoid(W*H)\n",
    "\n",
    "for i in range(I):\n",
    "    for j in range(J):\n",
    "        if not M[i,j]:\n",
    "            Y[i,j] = 8\n",
    "        else:\n",
    "            Y[i,j] = 1 if pi[i,j] < np.random.rand() else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: \n",
    "Given $Y$ and $M$ only find a good $W$ and $H$ by maximizing the objective $\\mathcal{L}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the gradient \n",
    "\n",
    "$$\n",
    "\\frac{d\\mathcal{L}(W,H)}{dW(i)} = \\sum_{j=1}^J (M(i,j) (Y(i,j) -\\sigma(W(i) H(j)))) H(j)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{d\\mathcal{L}(W,H)}{dH(j)} = \\sum_{i=1}^I  W(i) (M(i,j) (Y(i,j) -\\sigma(W(i) H(j))))\n",
    "$$\n",
    "\n",
    "\n",
    "Then use alternating gradient descent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exam Solution\n",
    "W = np.random.randn(I,1)\n",
    "H = np.random.randn(1,J)\n",
    "M = np.random.randn(5,10)\n",
    "for i in range(I):\n",
    "    for j in range(J):\n",
    "        if Y[i,j]==8:  # 8 is random number, different from 1 or 0.\n",
    "            M[i,j] = 0\n",
    "        else:\n",
    "            M[i,j] = 1\n",
    "\n",
    "\n",
    "\n",
    "def derivW(W,H,Y,M):    \n",
    "        dW = np.dot((Y - sigmoid(W@H))*M, H.T)\n",
    "        return dW\n",
    "def derivH(W,H,Y,M):        \n",
    "        dH = np.dot(W.T, (Y - sigmoid(W@H))*M)\n",
    "        return dH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36867974]\n",
      " [ 1.67555383]\n",
      " [ 0.28436594]\n",
      " [-1.03439405]\n",
      " [ 0.02769962]]\n",
      "[[-0.68860129 -0.4203127   0.68293204  1.55542938  0.11433369  0.32687149\n",
      "  -0.70587784 -1.26206165 -1.94302155 -1.13503902]]\n",
      "[[-0.21105466]\n",
      " [ 9.15795179]\n",
      " [ 1.65496489]\n",
      " [-0.5040525 ]\n",
      " [-3.60765563]]\n",
      "[[ 0.11712464  0.91811677 -0.18365208 -0.41202653 -6.77143038 -0.38875476\n",
      "  -1.2208713   2.48971455 -7.02930691  1.59158446]]\n",
      "[[ -0.19949909]\n",
      " [ 12.35334345]\n",
      " [  1.81814311]\n",
      " [ -0.41254509]\n",
      " [ -3.96472607]]\n",
      "[[ 0.11018265  0.96000762 -0.15479401 -0.34202185 -9.05912342 -0.32433402\n",
      "  -1.31101864  2.54706616 -9.20902709  1.53426448]]\n",
      "[[ -0.18826822]\n",
      " [ 14.68730146]\n",
      " [  1.8887896 ]\n",
      " [ -0.36649113]\n",
      " [ -4.17279528]]\n",
      "[[  0.10383542   0.98828251  -0.13947015  -0.3118918  -10.70966673\n",
      "   -0.29643611  -1.36586485   2.57178291 -10.81421645   1.5244571 ]]\n",
      "[[ -0.17795366]\n",
      " [ 16.57395796]\n",
      " [  1.91295554]\n",
      " [ -0.33773934]\n",
      " [ -4.36463999]]\n",
      "[[  0.09807003   1.00969544  -0.12808474  -0.29647235 -12.04001865\n",
      "   -0.28219509  -1.40603047   2.6314285  -12.11969525   1.53664349]]\n",
      "[[ -0.16903491]\n",
      " [ 18.18420758]\n",
      " [  1.91435724]\n",
      " [ -0.31734644]\n",
      " [ -4.5505973 ]]\n",
      "[[  0.09306539   1.02817889  -0.1190373   -0.28794329 -13.17536474\n",
      "   -0.27437797  -1.44038025   2.70710753 -13.23939081   1.55813741]]\n",
      "[[ -0.16132892]\n",
      " [ 19.60626465]\n",
      " [  1.90301735]\n",
      " [ -0.30161557]\n",
      " [ -4.73056129]]\n",
      "[[  0.08875034   1.04576554  -0.11161365  -0.28322816 -14.17830954\n",
      "   -0.27014117  -1.47272629   2.7900993  -14.23160742   1.58492688]]\n",
      "[[ -0.15460256]\n",
      " [ 20.89173817]\n",
      " [  1.88420483]\n",
      " [ -0.28876059]\n",
      " [ -4.9031308 ]]\n",
      "[[  0.08501886   1.06346327  -0.10540127  -0.28080086 -15.085014\n",
      "   -0.26807239  -1.50468505   2.87642761 -15.13051288   1.61514138]]\n",
      "[[ -0.14867174]\n",
      " [ 22.07342356]\n",
      " [  1.86121945]\n",
      " [ -0.27782837]\n",
      " [ -5.06687179]]\n",
      "[[  0.08177661   1.08169641  -0.10013424  -0.27977636 -15.91835537\n",
      "   -0.26734703  -1.5367899    2.96384117 -15.95793641   1.64749922]]\n",
      "[[ -0.14339894]\n",
      " [ 23.17336814]\n",
      " [  1.83627586]\n",
      " [ -0.26827679]\n",
      " [ -5.22071861]]\n",
      "[[  0.07894517   1.10054872  -0.09562571  -0.27959946 -16.69371395\n",
      "   -0.2674414   -1.56903142   3.05086528 -16.72865564   1.68097446]]\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 100000\n",
    "eta = 0.005\n",
    "\n",
    "for i in range (EPOCH):\n",
    "    W = W + eta * derivW(W,H,Y,M)\n",
    "    H = H + eta * derivH(W,H,Y,M)\n",
    "    if i % 10000 == 0:\n",
    "        print(W)\n",
    "        print(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
